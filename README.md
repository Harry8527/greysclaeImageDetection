Overview:

This project we will build a machine learning model which will recognize the greyscale image of a handwritten digit between 0 to 9.
It is built using Pytorch neural network model.

-------------------------------------------------- Script detailed explanation ---------------------------------------------------------------------------------------------------------

Pre-requisite libraries of python:

1. Pytorch : It is a python based library developed by Meta(formerly named as Facebook) for building and training neural
   networks, and other machine learning models.
2. torchvision : It is a computer vision library built on top of Pytorch. It provides tools for image processing,
   transformations, datasets, and pretrained models to make deep learning on images easier.

"""
Code snippet:

---

Brief about dependencies:

from torch.import.nn, save, load
=> torch.nn = Contains layers, activation functions, and loss functions for building neural networks.
=> save, load = Use to save and load model parameters.

from PIL import Image
=> This is used to load the image. It has a function called as open(fp), which takes image name as an argument in fp.

from torch.optim import Adam
=> An optimization algorithms for updating weights during training.

from torch.utils.data import DataLoader
=> Helps load data efficiently in batches.

from tochvision import datasets
=> It provides built-in datasets, which we will load later to the training_data variable for training our model.

from torchvision.transforms import ToTensor
=> Converts images to pytorch tensors for processing. So, our trained classification model expects the image as Tensor object,
and our image is either a jpg or png format(which will be loaded using PIL). To convert that image to Tensor object we use ToTensor class.
=> ToTensor also normalizes the pixel values from [0,255] to [0.0, 1.0], which is important for training neural networks
effectively.

---

Load the MNIST Dataset

training_data = datasets.MNIST(root="data", download=True, train=True, transform=ToTensor())
dataset = DataLoader(training_data, 32)

dataset.MNIST => Download, and loads the MNIST dataset, and store it in training_data variable.
root = "data" => Its the folder or directory name("data") where MNIST dataset will be saved .
download=True => Download the dataset if its not already present.
train = True => Loads the training set. (not the test set) --
(
Brief about train for better understanding:
The training set is the data which your model used to train itself. It has both input and labels(output). Your model can adjusts its weight parameters in this case for
adjusting its predicted value compared to actual value using the loss function or cost function. The process in which training data is used is called fitting or training.
)
transform = ToTensor() => Convert images to Pytorh tensors, which will be used later for processing.

dataset = DataLoader(training_data, 32)
=> Creates a pytorch DataLoader object that loads the dataset(training_data) in batch size
of 32.
=> It returns an iterator which can be looped over, and where each sample batch size is 32 images.
=> Each MNIST image is of the size 28 X 28 pixels.
=> It has a total of 10 classes from 0-9.
"""

---

Define the Image Classifier model

class ImageClassifier(nn.Module):
def **init**(self): # This is a constructor of ImageClassifier neural network class, which has inherited nn.Module class.
super().**init**() # Calling the constructor of nn.Module(parent) class.
self.model = nn.Sequential(

# Sequential lets you define all the layers in a neat, and ordered container.Pytorch will pass the input data through all the layers step by step in a given order.

nn.Conv2d(1,32,(3,3)),
nn.ReLU(), # ReLU => Rectified Linear Unit.
nn.Conv2d(32,64, (3,3)),
nn.ReLU(),
nn.Conv2d(64, 64,(3,3)),
nn.ReLU(),
nn.Flatten(),

            nn.Linear(64 * (28-6)*(28-6), 10)
        )

    def forward(self, x):
        return self.model(x)

# nn.Conv2d(input_channels, output_channels, kernel_size, stride = 1, padding = 0) :

    => Conv2d() - Its a  2D- convulutional neural network model used in scanning the image through small filters(aka kernels), and produce feature maps that highlights different
    features patterns such as edges, textures, corners, etc.
    => input_channels => It usually tells the kind of input image, such as Greyscale(1), RGB(3), RGBA(4) and so on.
    => output_channels => This tells the number of output images or feature maps to be generated by the convultional neural network, or we can say, it defines the number of
    different filters you want to apply.
    => kernel_size - The size of the kernel or  the size  of the sliding window(example, (3,3) in our case)
    => stride - It defines how many pixels of input image we have to move ahead in each incrementation step.Its default value is 1.
    => padding - How many border of 0 we have to add around the input image to control the output size of the image. Its default value is 0.

    So Conv2d(1,32,(3,3)) means:
    Input image is 1-channel(greyscale image)
    It applies 32 different filters, and generates 32 output images or 32 different feature maps. Each highlighting different features of the image.
    Kernel size for each filter is 3*3.

# ReLU(Rectified ): Its an activation function used to introduce non-linearity in the neural network. So we are passing our Conv2d output to ReLU()

    Generally, this function is used to return the positive value for each feature map/output image pixel's value.
    It can't be applied to images but to any tensor(Conv2d) in the network.
    ReLU(nn) = max(0,nn) -- It is applied element-wise (to all the pixels in the image) and return the 0 if pixel value is negative, and returns the pixel value
    as is if it positive.

# nn.flatten: This function will take multi-dimensional input, and returns 1-D vector as output. Flatten only affects the sample, and not the batch.

    It means that if you have input = [10, 32, 22,22], i.e., you have 10 images, each image has 32 feature maps, and its height and width is 22, and 22 pixels respectively.
    So, after you apply input.flatten(), your output will be = [10, 32*22*22]. Notice that, the number of images before and after or your batch size of 10 remains unchanged.
    Only the shape of the image is flattened.
    Why we need flatten:
    Conv2d outputs data in 3D shape, and our fully connected layers[linear or dense] expects input as 1D vector. So we flatten the 3D output to feed into the linear layer.

    In  our case: Our Conv2d(64, 64, (3,3)) which translates as (64, 64, 28-6, 28-6): (Batch_size, number of feature maps, height, width)
    [
        The Conv2d image dimensions is 28 * 28.
        We are subtracting 6 from 28 because each Conv2d() will reduce the image size by 2 pixels and we have 3 layers of Conv2d().
    ]
    When we apply nn.flatten or Conv2d(64, 64, 22,22).flatten() it becomes as (64, 64*22*22), which we can pass to the linear() in the next step.

# nn.Linear(64*22*22, 10)

    nn.Linear(in_features, out_features) => its a fully connected layer in the neural network. This is where the prediction of output happens.
    Output =  Weight . Input + Bias (f_x = W . X + b)
    in_features = total number of input values. (example, flattened pixels or feature values.)
    out_features = number of output neurons. (often equal to the number of classes)

    In our case: nn.Linear(64*22*22, 10) = nn.Linear(30976, 10)
    30976 came from the flattened layer after Conv2d
    10 classes, as these are the number of values that can possibly be for classification in the MNIST dataset(0-9)
    The nn.Linear() will generate 10 raw output values, these are called logits, which w

# def forward(self, x):

    When you create a custom neural network ('ImageClassifier' class in our case) by inheriting nn.Module, we have to define forward() method. This function tells Pytorch
    how to pass data through the model. So, in this function 'x' in the input image tensor received from the user.

# return self.model(x)

    self.model(x) means: pass the input through the layers defined in self.model(in our case we have defined nn.Sequential block in the __init__() method).
    So our input tensor 'x' will be passed through each of those layers in sequential manner as 'Conv2d -> ReLU -> Flatten -> Linear'.

# clf = ImageClassifier().to('cpu') (clf is an abbreviation for classifier.)

=> Creating an instance of the model, and informs pytorch that all the calculation of this model should happen on the CPU.

# opt = Adam(clf.parameters(), lr = 1e-3) ('opt' is an abbreviation for optimizer)

=> This line sets up your optimizer, which is responsible for calculating your model parameters weights (W) based on the calculated loss.

# loss_fn = nn.CrossEntropyLoss()

=> This is used when your models needs to predict one class out of many classes. We can also say that, we use it to perform multi-class classification.

# if **name** == "**main**":

    This defines the starting point of the script. This line ensures that the code inside the block is not executed when this script is imported into
    another script, and should only be executed when the script is run directly from the console as python pytorchnn.py (where, pytorchnn.py is the python filename)

------------------------- Brief description of training the model snippets -------------------------------------------------------------------------------------------

What exactly is happening during the traning of a model?
In training we determine the weight(w) and bias(b) parameter(s) for the linear regression model (in our case it is the image classification model) in such a way that the loss(or
cost) function is minimum, and the predicted output value is as close as possible to the actual target output.

What's epoch?
An epoch is one complete pass through the entire training dataset. During 1 epoch, all training samples are passed through the network - meaning the input
is forwarded through all layers(a forward pass),the output is predicted, the loss is computed, and then backpropagation is used to update the model's parameters
(weight and biases) to minimize the loss.

Backpropagation
It is an algorithm used to compute the derivate of cost w.r.t. the parameter. (dJ(w,b)/dw or dJ(w,b)/db). The derivate of cost w.r.t. parameter is also known as gradient.

# for epoch in range(10):

    We are running the training for 10 epochs.

# for batch in dataset:

    For each epoch we will traverse the entire dataset.

# x, y = batch

    Our batch variable will hold 2 values, first will be the batch of input sample(in this case 32 MNIST images of handwritten digits), and second will be a target
    labels(the actual digit each image represents = from 0 to 9). So, after the assignment is successful, x will hold the input sample, and y will hold the target labels.
    Each value of x will be a batch of 32 images in a tensor shape like [32, 1, 28,28] for MNIST, where:
    32 - batch size
    1  - Number of channels - 1 (for greyscale)
    28, 28 - height, and width of the MNIST image.

# x,y = x.to('cpu'), y.to('cpu')

    Loading the input sample, and target label to the cpu for further processing.

# yhat = clf(x)

    We are calling the neural network image classification model, and passing the input batch 'x' to it as an argument for prediction. The predicted value will be stored
    in yhat variable. The predicted values are raw predicted outputs(aka logits), which will typically have a shape of [32,10].
    32 => as we have 32 images per batch.
    10 => class scores per image(score for classes 0-9). These values are logits yet, and not probability. To convert them to probability we pass them through Softmax activation
    function.

    # logits:
        Logits are raw predicted output values. They can be positive, negative, large, small unbound or bounded values. Think of them as unnormalized confidence scores.
        Softmax turns those logits into probabilities. Now, their value of confidence score for each class will range between 0 and 1, which indicates the probability of
        how much likely each input image belongs to that particular digit class among 0-9.

# loss = loss_fn(yhat, y)

    We are computing the loss between the predicted vs actual target labels. The larger the loss the worse the prediction, and it tells us how much to adjust the model's
    weights and biases parameters during training.
    This value of loss guides the optimizer(Adam in our case) to decide which weight should change,and by how much?

    shape of yhat = [32, 10] .. 10 indicates the probability of digit across 10 classes.
    shape of y = [32] as this is  a correct label value, it will be a single digit among 0-9.
    Pytorch automatically handles this shape difference in CrossEntropyLoss.

# opt.zero_grad()

    This step resets the value of gradients of all model parameters to 0  before computing gradients for the next batch. This approach ensures that the gradients calculated
    for the current batch are not affected by the gradient values from the previous batch.

    If we will not have this step then the gradient value from previous batch will influence/affect the current batch gradient calculation.

    Wrong approach example when we are not resetting the gradient value:
    For batch0, say:
    w1.grad = w1.grad + dJ/dw1
    w1.grad = 1.1 (assigning a random value to w1.grad, only for the sake of this explantion.)

    For batch1,
    w1.grad = w1.grad + dJ/dw1
    w1.grad = 1.1(prev. batch gradient value) + dJ/dw1

    We dont want this to happen, because this will cause incorrect weight updates, and our model will learn wrong things.
    So, to avoid this situations we always resets the gradient values for all the parameters to 0 before computing value for the gradient of next batch parameters.

    Correct approach example when we are resetting the gradient value:
    For batch0, say:
    w1.grad = w1.grad + dJ/dw1
    w1.grad = 1.1 (assigning a random value to w1.grad, only for the sake of this explantion.)

    For batch1,
    w1.grad = 0 (this is happen through opt.zero_grad() step)
    w1.grad = w1.grad + dJ/dw1
    w1.grad = 1.1(prev. batch gradient value) + dJ/dw1

# loss.backward()

    This step tell us how much each weight and bias in the model contributes to the errors, and store those value in parameter.grad variable.Now, these values of
    gradient will be used by the optimizer(Adam in our case) to update the value of model parameter.

    Like, w1 = w1 - learning_rate * dJ/dw1

# opt.step()

    This will calculate the value of learnable parameter(s) where the cost is minimum.
    Like w1 = w1 - learning_rate * dJ/dw1
         b = b - learning_rate * dJ/db

# with open('model_state.pt', 'wb') as f:

    The above statement will create a pytorch file with the name of model_state(if it does not already exist, and if it exists it will open that file ) in write-binary mode.
    It is commonly used to save the learned parameters value of the model.

# save(clf.state_dict(), f)

    Saving the values of learned parameters values(weights and biases) of neural network model 'clf' to the file object f, where 'clf' is the object of ImageClassifier class.
    The state_dict will return a dictionary that will contain all the learnable parameters  of the model 'clf' passed as an arguement.

------------ Using our trained model --------------------------------------------------------

# with open('model_state.pt', 'rb') as f:

    We are opening the file(model_state.pt) in read binary mode to read or load the saved model parameters, amd storing its reference in file object f.
    This file object is then used to read the saved 'state_dict'(i.e. our model's learned parameters)

# clf.load_state_dict(load(f))

    We are loading the saved state_dict(learned parameters) of the neural network model 'clf'.
    load(f) reads dictionary of learned model parameters from the file object 'f'.
    So, clf.load_state_dict(load(f)) will first:
        load(f): read the dictionary of model's learned parameter from file object 'f'. Then,
        clf.load_state_dict(...) : load this dictionary into the neural network model 'clf'.

# image = Image.open('number_6.png')

    Opening the image file and storing it into the variable named 'image'.

# image = image.convert('L')

    Convert the image to greyscale, as our trained classification model can only support prediction of greyscale images. (1 channel only)

# image = image.resize((28,28), Image.Resampling.BILINEAR)

    As the dimension of images in MNIST dataset is 28 X 28 pixels. Therefore we are resizing our input image to 28 X 28 as our model is trained on MNIST dataset, so it
    expects the input image of that specific dimension.
    # Image.Resampling.BILINEAR
        When we resize the original image then its pixel value needs to be adjusted to fit the new dimensions post resizing. This process is called as resampling.
        BILINEAR is one of the best resampling method. Its fast, and generate good quality images, making it ideas choice for  resampling.

# image_tensor = ToTensor()(image).unsqueeze(0).to('cpu')

    Our input image is either a jpg or png file, but our image classification model expects the input as a Pytorch tensor .To convert the image to a tensor, we use
    ToTensor() method from torchvision.transforms class. It also normalizes the pixel values from [0-255] to [0-1] range. We then use unsqueeze(0) to add a batch dimension,
    making the tensor shape [1, 1, 28, 28] which is [batch_size, channel, height, width]. Finally, we move the tensor to the CPU for processing by the model.

    ToTensor()(image)
    ToTensor() : This line is first creating an object of ToTensor() class, often called as 'tranform'.
    ToTensor()(image) : Using the transform object we are calling the __call__() internally of the ToTensor class by passing "image" as input argument, which will convert our
    jpg/png image to Pytorch tensor. It also normalizes our image pixel values from the range of [0,255] to [0.0,1.0]
    The shape of the image also gets rearranged here from [H X W X C] to [C X H X W], which is a standard format used by Pytorch.

    unsqueeze(0) -> unsqueeze(dim)
    Through 0 we are informing the Pytorch to add a new dimension at the 0th index of the tensor, which is the batch size.

# torch.argmax(clf(image_tensor)

    Our classification model returns the an image of shape [1, 10],where 1 is the batch size of the image, and 10 the number of classes(digits from 0 to 9).
    Now, when we pass this output through argmax() it will internally call Softmax(), which will convert this logits to probabilities.
    Then argmax is used to find the index of the highest probability, which corresponds to our prediction digit class.
    We can also say that argmax() returns the class of digit with the maximum probability. which is our model's final prediction.

Additional:
tensors
It is a core data structure in Pytorch(and other deep leaerning libraries like Tensorflow). We can think of it as generalized version of arrays.
It is like a datatype for deep learning models. Just like we use variables to store data in normal programming, we use tensors in deep learning
models to store and process data.
